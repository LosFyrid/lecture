id: evaluation-101-framework-judges
title: "Evaluation：如何判断“好 agent”（框架 + Judges）"
summary: |
  从“可预测代码的测试”转向“非确定性系统的评估”：用四大质量支柱定义好坏（effectiveness/efficiency/robustness/safety），并理解评估者谱系（metrics、LLM-as-judge、HITL）。
items:
  - type: md
    title: 学习目标
    body: |
      学完本课，你应该能够：

      - 解释为什么传统 QA/测试范式在 agent 上会失效（非确定性 + 多步放大 + 工具交互 + memory 漂移）。
      - 用 4 个支柱描述 agent quality：**Effectiveness / Efficiency / Robustness / Safety**。
      - 说清楚 outside-in 的评估顺序：先黑盒看价值，再打开盒子找原因。
      - 设计一个最小 evaluation harness（任务集 + 指标/评分准则 + 报告）。

  - type: md
    title: 为什么 agent 评估与传统测试不同
    body: |
      agent 让“质量”变成一个系统性问题，因为它通常具备：

      - **多步 trajectory**：早期一个小随机差异会在后续步骤被放大
      - **tool interaction**：环境是动态且不可控的（API 超时、网页结构变动、数据缺失）
      - **memory**：今天的行为可能被昨天的记忆改变（漂移与污染）
      - **multi-agent（如果存在）**：会出现涌现行为，难以归因

      因此评估对象不再是“最终回答”，而是：**整条轨迹 + 与环境交互的全过程**。

  - type: md
    title: 四大质量支柱（Track101 的评估坐标系）
    body: |
      你可以把 agent quality 看成 4 维向量：

      - **Effectiveness（目标达成）**：是否真正完成用户意图/任务目标？
      - **Efficiency（效率/成本）**：用多少 token/时间/步骤/工具调用完成？
      - **Robustness（鲁棒性）**：面对缺失信息、工具失败、歧义意图是否能优雅退化？
      - **Safety & Alignment（安全/对齐）**：是否遵守边界、抵抗注入/泄漏/越权？

      研究建议：不要把评估结果写成“通过/失败”二元；尽量用分布与置信区间表达（同一任务多次运行的结果分布）。

  - type: md
    title: Outside-In：先黑盒，再玻璃盒
    body: |
      推荐顺序：

      1) **End-to-End（黑盒）**：是否达成目标？（面向真实价值）  
      2) **Trajectory（玻璃盒）**：为什么成功/失败？（面向归因与改进）

      你可以把 trajectory 想成“实验过程记录”：没有过程记录，就无法解释失败，更无法复现。

  - type: html
    title: Judges（谁来评估）谱系：从自动到人类
    note: agent 评估往往是混合式：自动化指标 + LLM judge + 必要的人类审阅。
    body: |
      <div style="border:1px solid rgba(0,0,0,.12); border-radius:12px; padding:12px; line-height:1.65;">
        <div style="font-weight:600; margin-bottom:6px;">1) Automated metrics</div>
        <div>任务完成率、步骤数、token、latency、tool error rate、重试次数……（可规模化、可回归）</div>
        <div style="height:10px;"></div>
        <div style="font-weight:600; margin-bottom:6px;">2) LLM-as-a-judge</div>
        <div>用 rubric 评分（把“质量”从 pass/fail 变成连续尺度），但要注意 judge 本身偏差与漂移。</div>
        <div style="height:10px;"></div>
        <div style="font-weight:600; margin-bottom:6px;">3) Human-in-the-loop (HITL)</div>
        <div>人类提供高价值信号，但昂贵；需要结构化 UI/流程提升一致性。</div>
      </div>

  - type: md
    title: 最小 evaluation harness（研究起步版）
    body: |
      你可以用下面模板快速起步（后续会在 AgentOps 里把它接入 CI/CD）：

      1) **任务集（Task suite）**：10–50 个代表性任务 + 失败模式（缺失信息、工具超时、歧义意图）  
      2) **指标（Metrics）**：至少覆盖 4 支柱中的 2–3 个维度（先从 effectiveness/efficiency 开始也可以）  
      3) **评分准则（Rubric）**：对开放式回答，用 LLM judge 或专家评分  
      4) **报告（Report）**：成功率、成本分布、错误类型分布、典型轨迹样例

  - type: md
    layout: inline
    body: |
      原文节选建议：

      - 源 PDF：`Agent Quality.pdf`
      - 建议裁剪页码：第 **6–30** 页（对应章节：Paradigm shift / 4 pillars / Outside-In / judges / HITL / RAI & safety）

      裁剪后上传到 S3，再把下面 `assetKey` 更新为你的对象 key。
  - type: pdf
    title: "原文节选：Agent Quality（第 6–30 页）"
    assetKey: pdf/excerpts/Agent_Quality.p6-30.pdf

